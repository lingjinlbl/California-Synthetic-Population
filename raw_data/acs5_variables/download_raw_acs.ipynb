{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "# from census_helper import Census\n",
    "import requests\n",
    "import numpy as np\n",
    "import us\n",
    "import census\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "from typing import List"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open('acs5_variables_2018.json', 'r') as file:\n",
    "    data = file.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "parsed_data = json.loads(data)\n",
    "\n",
    "# Extract the group names\n",
    "group_names = list(parsed_data[\"variables\"].keys())\n",
    "filtered_variable_names = [name for name in group_names if re.match(r'[BC]\\d', name)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "26996"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtered_variable_names.sort()\n",
    "len(filtered_variable_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class Census:\n",
    "    '''\n",
    "    Note from Andrew: This class is taken directly from the synthpop package.\n",
    "    It was originally imported using:\n",
    "    from synthpop.census_helpers import Census\n",
    "    I don't really know much about this otherwise, other than that it works for querying ACS data.\n",
    "    You can probably query ACS data through a different method too, should this method from SynthPop stop working\n",
    "    Downloading PUMS data through this doesn't work through this, because it doesn't provide the serial number which we need\n",
    "    '''\n",
    "\n",
    "    def __init__(self, key):\n",
    "        self.c = census.Census(key)\n",
    "        self.base_url = \"https://s3-us-west-1.amazonaws.com/synthpop-data2/\"\n",
    "        self.pums_relationship_file_url = self.base_url + \"tract10_to_puma.csv\"\n",
    "        self.pums_relationship_df = None\n",
    "        self.pums10_population_base_url = \\\n",
    "            self.base_url + \"puma10_p_%s_%s.csv\"\n",
    "        self.pums10_household_base_url = \\\n",
    "            self.base_url + \"puma10_h_%s_%s.csv\"\n",
    "        self.pums00_population_base_url = \\\n",
    "            self.base_url + \"puma00_p_%s_%s.csv\"\n",
    "        self.pums00_household_base_url = \\\n",
    "            self.base_url + \"puma00_h_%s_%s.csv\"\n",
    "        self.pums_population_state_base_url = \\\n",
    "            self.base_url + \"puma_p_%s.csv\"\n",
    "        self.pums_household_state_base_url = \\\n",
    "            self.base_url + \"puma_h_%s.csv\"\n",
    "        self.fips_url = self.base_url + \"national_county.txt\"\n",
    "        self.fips_df = None\n",
    "        self.pums_cache = {}\n",
    "\n",
    "    # df1 is the disaggregate data frame (e.g. block groups)\n",
    "    # df2 is the aggregate data frame (e.g. tracts)\n",
    "    # need to scale down df2 variables to df1 level totals\n",
    "    def _scale_and_merge(self, df1, tot1, df2, tot2, columns_to_scale,\n",
    "                         merge_columns, suffixes):\n",
    "        df = pd.merge(df1, df2, left_on=merge_columns, right_on=merge_columns,\n",
    "                      suffixes=suffixes)\n",
    "\n",
    "        # going to scale these too so store current values\n",
    "        tot2, tot1 = df[tot2], df[tot1]\n",
    "        # if agg number if 0, disaggregate should be 0\n",
    "        # note this is filled by fillna below\n",
    "        assert np.all(tot1[tot2 == 0] == 0)\n",
    "\n",
    "        for col in columns_to_scale:\n",
    "            df[col] = df[col] / tot2 * tot1\n",
    "            # round?\n",
    "            df[col] = df[col].fillna(0).astype('int')\n",
    "        return df\n",
    "\n",
    "    def block_group_query(self, census_columns, state, county, year=2016,\n",
    "                          tract=None, id=None):\n",
    "        if id is None:\n",
    "            id = \"*\"\n",
    "        return self._query(census_columns, state, county,\n",
    "                           forstr=\"block group:%s\" % id,\n",
    "                           tract=tract, year=year)\n",
    "\n",
    "    def tract_query(self, census_columns, state, county, year=2016,\n",
    "                    tract=None):\n",
    "        if tract is None:\n",
    "            tract = \"*\"\n",
    "        return self._query(census_columns, state, county,\n",
    "                           forstr=\"tract:%s\" % tract,\n",
    "                           year=year)\n",
    "\n",
    "    def _query(self, census_columns, state, county, forstr,\n",
    "               year, tract=None):\n",
    "        c = self.c\n",
    "\n",
    "        state, county = self.try_fips_lookup(state, county)\n",
    "\n",
    "        if tract is None:\n",
    "            in_str = 'state:%s county:%s' % (state, county)\n",
    "        else:\n",
    "            in_str = 'state:%s county:%s tract:%s' % (state, county, tract)\n",
    "\n",
    "        dfs = []\n",
    "\n",
    "        # unfortunately the api only queries 50 columns at a time\n",
    "        # leave room for a few extra id columns\n",
    "        def chunks(l, n):\n",
    "            \"\"\" Yield successive n-sized chunks from l.\n",
    "            \"\"\"\n",
    "            for i in range(0, len(l), n):\n",
    "                yield l[i:i + n]\n",
    "\n",
    "        for census_column_batch in chunks(census_columns, 45):\n",
    "            census_column_batch = list(census_column_batch)\n",
    "            # print(census_column_batch)\n",
    "            d = c.acs5.get(['NAME'] + census_column_batch,\n",
    "                           geo={'for': forstr,\n",
    "                                'in': in_str}, year=year)\n",
    "            # print(d)\n",
    "            df = pd.DataFrame(d)\n",
    "            # df[census_column_batch] = df[census_column_batch].astype('int') # This is the original, however it runs into problems if the value is None or NA\n",
    "            for name in census_column_batch: # This is the new added for loop as a replacement for the previous line\n",
    "                if df[name].dtype == 'int64':\n",
    "                    df[name] = df[name].astype('int')\n",
    "            dfs.append(df)\n",
    "\n",
    "        assert len(dfs) >= 1\n",
    "        df = dfs[0]\n",
    "        for mdf in dfs[1:]:\n",
    "            df = pd.merge(df, mdf, on=\"NAME\", suffixes=(\"\", \"_ignore\"))\n",
    "            drop_cols = list(filter(lambda x: \"_ignore\" in x, df.columns))\n",
    "            df = df.drop(drop_cols, axis=1)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def block_group_and_tract_query(self, block_group_columns,\n",
    "                                    tract_columns, state, county,\n",
    "                                    merge_columns, block_group_size_attr,\n",
    "                                    tract_size_attr, year=2016, tract=None):\n",
    "        df2 = self.tract_query(tract_columns, state, county, tract=tract,\n",
    "                               year=year)\n",
    "        df1 = self.block_group_query(block_group_columns, state, county,\n",
    "                                     tract=tract, year=year)\n",
    "\n",
    "        df = self._scale_and_merge(df1, block_group_size_attr, df2,\n",
    "                                   tract_size_attr, tract_columns,\n",
    "                                   merge_columns, suffixes=(\"\", \"_ignore\"))\n",
    "        drop_cols = list(filter(lambda x: \"_ignore\" in x, df.columns))\n",
    "        df = df.drop(drop_cols, axis=1)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _get_pums_relationship(self):\n",
    "        if self.pums_relationship_df is None:\n",
    "            self.pums_relationship_df = \\\n",
    "                pd.read_csv(self.pums_relationship_file_url, dtype={\n",
    "                    \"statefp\": \"object\",\n",
    "                    \"countyfp\": \"object\",\n",
    "                    \"tractce\": \"object\",\n",
    "                    \"puma10_id\": \"object\",\n",
    "                    \"puma00_id\": \"object\",\n",
    "                })\n",
    "        return self.pums_relationship_df\n",
    "\n",
    "    def _get_fips_lookup(self):\n",
    "        if self.fips_df is None:\n",
    "            self.fips_df = pd.read_csv(\n",
    "                self.fips_url,\n",
    "                dtype={\n",
    "                    \"State ANSI\": \"object\",\n",
    "                    \"County ANSI\": \"object\"\n",
    "                },\n",
    "                index_col=[\"State\",\n",
    "                           \"County Name\"]\n",
    "            )\n",
    "            del self.fips_df[\"ANSI Cl\"]\n",
    "        return self.fips_df\n",
    "\n",
    "    def tract_to_puma(self, state, county, tract):\n",
    "\n",
    "        state, county = self.try_fips_lookup(state, county)\n",
    "\n",
    "        df = self._get_pums_relationship()\n",
    "        q = \"statefp == '%s' and countyfp == '%s' and tractce == '%s'\" % (\n",
    "            state, county, tract)\n",
    "        r = df.query(q)\n",
    "        return r[\"puma10_id\"].values[0], r[\"puma00_id\"].values[0]\n",
    "\n",
    "    def _read_csv(self, loc, **kargs):\n",
    "        if loc not in self.pums_cache:\n",
    "            pums_df = pd.read_csv(loc, dtype={\n",
    "                \"PUMA10\": \"object\",\n",
    "                \"PUMA00\": \"object\",\n",
    "                \"ST\": \"object\"\n",
    "            }, **kargs)\n",
    "            pums_df = pums_df.rename(columns={\n",
    "                'PUMA10': 'puma10',\n",
    "                'PUMA00': 'puma00',\n",
    "                'SERIALNO': 'serialno'\n",
    "            })\n",
    "            self.pums_cache[loc] = pums_df\n",
    "        return self.pums_cache[loc]\n",
    "\n",
    "    def download_population_pums(self, state, puma10=None, puma00=None,\n",
    "                                 **kargs):\n",
    "        state = self.try_fips_lookup(state)\n",
    "        if (puma10 is None) & (puma00 is None):\n",
    "            return self._read_csv(self.pums_population_state_base_url % (state),\n",
    "                                  **kargs)\n",
    "        pums = self._read_csv(self.pums10_population_base_url % (state, puma10),\n",
    "                              **kargs)\n",
    "        if puma00 is not None:\n",
    "            pums00 = self._read_csv(\n",
    "                self.pums00_population_base_url % (state, puma00), **kargs)\n",
    "            pums = pd.concat([pums, pums00], ignore_index=True)\n",
    "        return pums\n",
    "\n",
    "    def download_household_pums(self, state, puma10=None, puma00=None, **kargs):\n",
    "        state = self.try_fips_lookup(state)\n",
    "        if (puma10 is None) & (puma00 is None):\n",
    "            return self._read_csv(self.pums_household_state_base_url % (state),\n",
    "                                  **kargs)\n",
    "        pums = self._read_csv(self.pums10_household_base_url % (state, puma10),\n",
    "                              **kargs)\n",
    "        if puma00 is not None:\n",
    "            pums00 = self._read_csv(\n",
    "                self.pums00_household_base_url % (state, puma00), **kargs)\n",
    "            pums = pd.concat([pums, pums00], ignore_index=True)\n",
    "\n",
    "        # filter out gq and empty units (non-hh records)\n",
    "        pums = pums[(pums.RT == 'H') & (pums.NP > 0) & (pums.TYPE == 1)]\n",
    "\n",
    "        return pums\n",
    "\n",
    "    def try_fips_lookup(self, state, county=None):\n",
    "        df = self._get_fips_lookup()\n",
    "\n",
    "        if county is None:\n",
    "            try:\n",
    "                return getattr(us.states, state).fips\n",
    "            except:\n",
    "                pass\n",
    "            return state\n",
    "\n",
    "        try:\n",
    "            return df.loc[(state, county)]\n",
    "        except:\n",
    "            pass\n",
    "        return state, county\n",
    "\n",
    "# import time\n",
    "# c = Census(\"285e70bec59918991430e98163a4cda2802b4f01\")\n",
    "#\n",
    "# income_columns = ['B19001_0%02dE' % i for i in range(1, 18)]\n",
    "# hhsize_columns = ['B11016_0%02dE' % i for i in range(1, 17)]\n",
    "# hhrace_columns = ['B25006_0%02dE' % i for i in range(1, 11)]\n",
    "# hhown_columns = ['B25003_0%02dE' % i for i in range(1, 4)]\n",
    "# work_columns = ['B08202_0%02dE' % i for i in range(1, 6)]\n",
    "# child_column = ['B11005_002E']\n",
    "# tract_columns = (income_columns + hhsize_columns + hhrace_columns +\n",
    "#                 hhown_columns + work_columns + child_column)\n",
    "#\n",
    "# start_time = time.time()\n",
    "# h_acs = c.tract_query(tract_columns, state='06', county='001',year=2018)\n",
    "# end_time = time.time()\n",
    "# # Calculate the elapsed time\n",
    "# elapsed_time = end_time - start_time\n",
    "#\n",
    "# # Print the elapsed time\n",
    "# print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "state = '06'  # FIPS code for the state\n",
    "county = '001'  # FIPS code for the county\n",
    "year = 2020  # ACS year you want to query from as an int. Works up to 2019\n",
    "\n",
    "logging.info('Downloading ACS Marginals for: State = ' +\n",
    "            state + ', County = ' + county + ', Year = ' + str(year))\n",
    "\n",
    "# this a key needed to access te Census API\n",
    "c = Census(\"285e70bec59918991430e98163a4cda2802b4f01\")\n",
    "\n",
    "    # Extract the columns we need for households\n",
    "    # Column names: https://api.census.gov/data/2018/acs/acs5/variables.html\n",
    "logging.info('Downloading raw household marginals...')\n",
    "\n",
    "income_columns = ['B19001_0%02dE' % i for i in range(1, 18)]\n",
    "hhsize_columns = ['B11016_0%02dE' % i for i in range(1, 17)]\n",
    "hhrace_columns = ['B25006_0%02dE' % i for i in range(1, 11)]\n",
    "hhown_columns = ['B25003_0%02dE' % i for i in range(1, 4)]\n",
    "work_columns = ['B08202_0%02dE' % i for i in range(1, 6)]\n",
    "child_column = ['B11005_002E']\n",
    "tract_columns = (income_columns + hhsize_columns + hhrace_columns +\n",
    "                hhown_columns + work_columns + child_column)\n",
    "\n",
    "    # Downloads the ACS totals at the Census Tract level\n",
    "h_acs = c.tract_query(tract_columns, state=state, county=county,\n",
    "                          year=year)\n",
    "logging.info('Raw household marginal download complete!')\n",
    "\n",
    "    # Extract the columns we need for people\n",
    "    # Column names: https://api.census.gov/data/2018/acs/acs5/variables.html\n",
    "\n",
    "logging.info('Downloading person marginals...')\n",
    "population = ['B01001_001E']\n",
    "sex = ['B01001_002E', 'B01001_026E']\n",
    "race = ['B02001_0%02dE' % i for i in range(1, 11)]\n",
    "male_age_columns = ['B01001_0%02dE' % i for i in range(3, 26)]\n",
    "female_age_columns = ['B01001_0%02dE' % i for i in range(27, 50)]\n",
    "all_columns = population + sex + race + male_age_columns + female_age_columns\n",
    "p_acs = c.tract_query(all_columns, state=state, county=county, year=year)\n",
    "logging.info('Person marginal download complete!')\n",
    "\n",
    "    # Create geo_cross_walk.csv.\n",
    "    # Basically this shows the relationship between each tract, PUMA\n",
    "\n",
    "logging.info('Creating geo_cross_walk file...')\n",
    "    # %%\n",
    "column_names = ['TRACT', 'PUMA', 'REGION']\n",
    "geo_cross_walk = pd.DataFrame(columns=column_names)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "file_path = '../tract_to_puma/2010_Census_Tract_to_2010_PUMA.txt'\n",
    "\n",
    "# Read the text file using pandas\n",
    "data = pd.read_csv(file_path, delimiter=',')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "       STATEFP  COUNTYFP  TRACTCE  PUMA5CE\n0            1         1    20100     2100\n1            1         1    20200     2100\n2            1         1    20300     2100\n3            1         1    20400     2100\n4            1         1    20500     2100\n...        ...       ...      ...      ...\n74086       78        30   960900      100\n74087       78        30   961000      100\n74088       78        30   961100      100\n74089       78        30   961200      100\n74090       78        30   990000      100\n\n[74091 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>STATEFP</th>\n      <th>COUNTYFP</th>\n      <th>TRACTCE</th>\n      <th>PUMA5CE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>20100</td>\n      <td>2100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>20200</td>\n      <td>2100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>1</td>\n      <td>20300</td>\n      <td>2100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>20400</td>\n      <td>2100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1</td>\n      <td>20500</td>\n      <td>2100</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74086</th>\n      <td>78</td>\n      <td>30</td>\n      <td>960900</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>74087</th>\n      <td>78</td>\n      <td>30</td>\n      <td>961000</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>74088</th>\n      <td>78</td>\n      <td>30</td>\n      <td>961100</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>74089</th>\n      <td>78</td>\n      <td>30</td>\n      <td>961200</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>74090</th>\n      <td>78</td>\n      <td>30</td>\n      <td>990000</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n<p>74091 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "puma = data[(data['STATEFP'] == int(state)) & (data['COUNTYFP'] == int(county)) & (data['TRACTCE'] == int('420100'))]['PUMA5CE']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "3560    101\nName: PUMA5CE, dtype: int64"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puma"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "102\n",
      "102\n",
      "107\n",
      "107\n",
      "107\n",
      "108\n",
      "109\n",
      "108\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "108\n",
      "109\n",
      "109\n",
      "110\n",
      "110\n",
      "110\n",
      "102\n",
      "103\n",
      "102\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "102\n",
      "102\n",
      "103\n",
      "107\n",
      "105\n",
      "106\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "110\n",
      "104\n",
      "104\n",
      "110\n",
      "102\n",
      "103\n",
      "103\n",
      "102\n",
      "102\n",
      "107\n",
      "108\n",
      "104\n",
      "101\n",
      "105\n",
      "109\n",
      "109\n",
      "110\n",
      "102\n",
      "103\n",
      "108\n",
      "108\n",
      "108\n",
      "109\n",
      "110\n",
      "110\n",
      "103\n",
      "103\n",
      "102\n",
      "102\n",
      "103\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "104\n",
      "102\n",
      "109\n",
      "108\n",
      "108\n",
      "109\n",
      "108\n",
      "108\n",
      "110\n",
      "110\n",
      "110\n",
      "110\n",
      "110\n",
      "110\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "103\n",
      "103\n",
      "102\n",
      "102\n",
      "102\n",
      "104\n",
      "102\n",
      "102\n",
      "104\n",
      "102\n",
      "104\n",
      "104\n",
      "102\n",
      "102\n",
      "104\n",
      "104\n",
      "104\n",
      "103\n",
      "104\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "103\n",
      "105\n",
      "106\n",
      "106\n",
      "105\n",
      "105\n",
      "105\n",
      "102\n",
      "102\n",
      "102\n",
      "103\n",
      "104\n",
      "104\n",
      "104\n",
      "108\n",
      "109\n",
      "101\n",
      "109\n",
      "109\n",
      "109\n",
      "108\n",
      "108\n",
      "110\n",
      "110\n",
      "110\n",
      "109\n",
      "107\n",
      "106\n",
      "107\n",
      "107\n",
      "108\n",
      "107\n",
      "108\n",
      "108\n",
      "108\n",
      "109\n",
      "109\n",
      "109\n",
      "110\n",
      "110\n",
      "110\n",
      "110\n",
      "110\n",
      "101\n",
      "101\n",
      "101\n",
      "110\n",
      "110\n",
      "110\n",
      "110\n",
      "110\n",
      "110\n",
      "110\n",
      "110\n",
      "110\n",
      "110\n",
      "101\n",
      "101\n",
      "103\n",
      "102\n",
      "102\n",
      "105\n",
      "102\n",
      "103\n",
      "102\n",
      "102\n",
      "103\n",
      "102\n",
      "102\n",
      "110\n",
      "110\n",
      "102\n",
      "102\n",
      "102\n",
      "106\n",
      "106\n",
      "102\n",
      "105\n",
      "105\n",
      "109\n",
      "108\n",
      "110\n",
      "110\n",
      "106\n",
      "106\n",
      "107\n",
      "107\n",
      "101\n",
      "101\n",
      "101\n",
      "105\n",
      "105\n",
      "106\n",
      "106\n",
      "105\n",
      "106\n",
      "105\n",
      "105\n",
      "105\n",
      "107\n",
      "107\n",
      "106\n",
      "106\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "107\n",
      "108\n",
      "110\n",
      "105\n",
      "109\n",
      "108\n",
      "106\n",
      "107\n",
      "109\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "106\n",
      "105\n",
      "107\n",
      "107\n",
      "101\n",
      "105\n",
      "105\n",
      "106\n",
      "105\n",
      "105\n",
      "106\n",
      "106\n",
      "107\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "109\n",
      "109\n",
      "110\n",
      "110\n",
      "110\n",
      "103\n",
      "102\n",
      "103\n",
      "103\n",
      "104\n",
      "105\n",
      "103\n",
      "103\n",
      "101\n",
      "101\n",
      "101\n",
      "106\n",
      "106\n",
      "105\n",
      "105\n",
      "106\n",
      "104\n",
      "101\n",
      "102\n",
      "102\n",
      "104\n",
      "104\n",
      "103\n",
      "103\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "105\n",
      "106\n",
      "106\n",
      "106\n",
      "103\n",
      "103\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "103\n",
      "102\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "103\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "106\n",
      "106\n",
      "107\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "109\n",
      "101\n",
      "101\n",
      "107\n",
      "107\n",
      "104\n",
      "110\n",
      "109\n",
      "110\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "106\n",
      "106\n",
      "104\n",
      "104\n",
      "104\n",
      "101\n",
      "101\n",
      "101\n",
      "101\n",
      "105\n",
      "101\n",
      "105\n"
     ]
    }
   ],
   "source": [
    "if year >= 2020:\n",
    "    raw_xwalk_path = '../tract_to_puma/2020_Census_Tract_to_2020_PUMA.txt'\n",
    "else:\n",
    "    raw_xwalk_path = '../tract_to_puma/2010_Census_Tract_to_2010_PUMA.txt'\n",
    "\n",
    "raw_xwalk = pd.read_csv(raw_xwalk_path, delimiter=',')\n",
    "\n",
    "puma_codes_unique = []\n",
    "puma_codes_all = []\n",
    "\n",
    "for tract in h_acs['tract']:\n",
    "    code = raw_xwalk[(raw_xwalk['STATEFP'] == int(state)) & (raw_xwalk['COUNTYFP'] == int(county)) & (raw_xwalk['TRACTCE'] == int(tract))]['PUMA5CE'].item()\n",
    "    if code not in puma_codes_unique:\n",
    "        puma_codes_unique.append(code)\n",
    "    puma_codes_all.append(int(code))\n",
    "h_acs['PUMA'] = puma_codes_all"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "tracts = []\n",
    "tract_relationship_path = '../tract_to_puma/2020_Census_Tract_to_2010_Census_Tract.txt'\n",
    "tract_relationship = pd.read_csv(tract_relationship_path, delimiter='|', dtype = {'GEOID_TRACT_20': str, 'GEOID_TRACT_10': str})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "           OID_TRACT_20 GEOID_TRACT_20  NAMELSAD_TRACT_20  AREALAND_TRACT_20  \\\n0        20790540092527    01001020100   Census Tract 201            9825304   \n1        20790540092527    01001020100   Census Tract 201            9825304   \n2        20790540092534    01001020200   Census Tract 202            3320818   \n3        20790540092528    01001020300   Census Tract 203            5349271   \n4        20790540092529    01001020400   Census Tract 204            6384282   \n...                 ...            ...                ...                ...   \n126445  207904252102449    78030961100  Census Tract 9611            3479232   \n126446   20790228304757    78030961200  Census Tract 9612            1101324   \n126447   20790228304757    78030961200  Census Tract 9612            1101324   \n126448   20790228304757    78030961200  Census Tract 9612            1101324   \n126449   20790228304801    78030990000  Census Tract 9900                  0   \n\n        AREAWATER_TRACT_20 MTFCC_TRACT_20 FUNCSTAT_TRACT_20     OID_TRACT_10  \\\n0                    28435          G5020                 S   20740540092527   \n1                    28435          G5020                 S   20740540092534   \n2                     5669          G5020                 S   20740540092534   \n3                     9054          G5020                 S   20740540092528   \n4                     8408          G5020                 S   20740540092529   \n...                    ...            ...               ...              ...   \n126445                   0          G5020                 S   20740228304757   \n126446              802134          G5020                 S   20740228304707   \n126447              802134          G5020                 S  207404252102449   \n126448              802134          G5020                 S   20740228304757   \n126449           687337537          G5020                 S   20740228304801   \n\n       GEOID_TRACT_10  NAMELSAD_TRACT_10  AREALAND_TRACT_10  \\\n0         01001020100   Census Tract 201            9827271   \n1         01001020200   Census Tract 202            3325674   \n2         01001020200   Census Tract 202            3325674   \n3         01001020300   Census Tract 203            5349271   \n4         01001020400   Census Tract 204            6384282   \n...               ...                ...                ...   \n126445    78030961200  Census Tract 9612            1017540   \n126446    78030960400  Census Tract 9604           11709358   \n126447    78030961100  Census Tract 9611            3513895   \n126448    78030961200  Census Tract 9612            1017540   \n126449    78030990000  Census Tract 9900                  0   \n\n        AREAWATER_TRACT_10 MTFCC_TRACT_10 FUNCSTAT_TRACT_10  AREALAND_PART  \\\n0                    28435          G5020                 S        9820448   \n1                     5669          G5020                 S           4856   \n2                     5669          G5020                 S        3320818   \n3                     9054          G5020                 S        5349271   \n4                     8408          G5020                 S        6384282   \n...                    ...            ...               ...            ...   \n126445              802134          G5020                 S          14104   \n126446              413661          G5020                 S         217781   \n126447                   0          G5020                 S            203   \n126448              802134          G5020                 S         883340   \n126449           687428211          G5020                 S              0   \n\n        AREAWATER_PART  \n0                28435  \n1                    0  \n2                 5669  \n3                 9054  \n4                 8408  \n...                ...  \n126445               0  \n126446               0  \n126447               0  \n126448          802134  \n126449       687337537  \n\n[126450 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OID_TRACT_20</th>\n      <th>GEOID_TRACT_20</th>\n      <th>NAMELSAD_TRACT_20</th>\n      <th>AREALAND_TRACT_20</th>\n      <th>AREAWATER_TRACT_20</th>\n      <th>MTFCC_TRACT_20</th>\n      <th>FUNCSTAT_TRACT_20</th>\n      <th>OID_TRACT_10</th>\n      <th>GEOID_TRACT_10</th>\n      <th>NAMELSAD_TRACT_10</th>\n      <th>AREALAND_TRACT_10</th>\n      <th>AREAWATER_TRACT_10</th>\n      <th>MTFCC_TRACT_10</th>\n      <th>FUNCSTAT_TRACT_10</th>\n      <th>AREALAND_PART</th>\n      <th>AREAWATER_PART</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20790540092527</td>\n      <td>01001020100</td>\n      <td>Census Tract 201</td>\n      <td>9825304</td>\n      <td>28435</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>20740540092527</td>\n      <td>01001020100</td>\n      <td>Census Tract 201</td>\n      <td>9827271</td>\n      <td>28435</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>9820448</td>\n      <td>28435</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20790540092527</td>\n      <td>01001020100</td>\n      <td>Census Tract 201</td>\n      <td>9825304</td>\n      <td>28435</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>20740540092534</td>\n      <td>01001020200</td>\n      <td>Census Tract 202</td>\n      <td>3325674</td>\n      <td>5669</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>4856</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>20790540092534</td>\n      <td>01001020200</td>\n      <td>Census Tract 202</td>\n      <td>3320818</td>\n      <td>5669</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>20740540092534</td>\n      <td>01001020200</td>\n      <td>Census Tract 202</td>\n      <td>3325674</td>\n      <td>5669</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>3320818</td>\n      <td>5669</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20790540092528</td>\n      <td>01001020300</td>\n      <td>Census Tract 203</td>\n      <td>5349271</td>\n      <td>9054</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>20740540092528</td>\n      <td>01001020300</td>\n      <td>Census Tract 203</td>\n      <td>5349271</td>\n      <td>9054</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>5349271</td>\n      <td>9054</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>20790540092529</td>\n      <td>01001020400</td>\n      <td>Census Tract 204</td>\n      <td>6384282</td>\n      <td>8408</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>20740540092529</td>\n      <td>01001020400</td>\n      <td>Census Tract 204</td>\n      <td>6384282</td>\n      <td>8408</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>6384282</td>\n      <td>8408</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>126445</th>\n      <td>207904252102449</td>\n      <td>78030961100</td>\n      <td>Census Tract 9611</td>\n      <td>3479232</td>\n      <td>0</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>20740228304757</td>\n      <td>78030961200</td>\n      <td>Census Tract 9612</td>\n      <td>1017540</td>\n      <td>802134</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>14104</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>126446</th>\n      <td>20790228304757</td>\n      <td>78030961200</td>\n      <td>Census Tract 9612</td>\n      <td>1101324</td>\n      <td>802134</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>20740228304707</td>\n      <td>78030960400</td>\n      <td>Census Tract 9604</td>\n      <td>11709358</td>\n      <td>413661</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>217781</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>126447</th>\n      <td>20790228304757</td>\n      <td>78030961200</td>\n      <td>Census Tract 9612</td>\n      <td>1101324</td>\n      <td>802134</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>207404252102449</td>\n      <td>78030961100</td>\n      <td>Census Tract 9611</td>\n      <td>3513895</td>\n      <td>0</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>203</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>126448</th>\n      <td>20790228304757</td>\n      <td>78030961200</td>\n      <td>Census Tract 9612</td>\n      <td>1101324</td>\n      <td>802134</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>20740228304757</td>\n      <td>78030961200</td>\n      <td>Census Tract 9612</td>\n      <td>1017540</td>\n      <td>802134</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>883340</td>\n      <td>802134</td>\n    </tr>\n    <tr>\n      <th>126449</th>\n      <td>20790228304801</td>\n      <td>78030990000</td>\n      <td>Census Tract 9900</td>\n      <td>0</td>\n      <td>687337537</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>20740228304801</td>\n      <td>78030990000</td>\n      <td>Census Tract 9900</td>\n      <td>0</td>\n      <td>687428211</td>\n      <td>G5020</td>\n      <td>S</td>\n      <td>0</td>\n      <td>687337537</td>\n    </tr>\n  </tbody>\n</table>\n<p>126450 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tract_relationship"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "old_tract = int(tract_relationship[tract_relationship['GEOID_TRACT_20'] == '06001402801'].iloc[0]['GEOID_TRACT_10'][5:])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "402700"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tract"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "\n",
    "for tract in h_acs['tract']:\n",
    "    geoid_tract_20 = state + county + str(tract)\n",
    "    tracts.append(int(tract_relationship[tract_relationship['GEOID_TRACT_20'] == geoid_tract_20].iloc[0]['GEOID_TRACT_10'][5:]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[400100,\n 400200,\n 400300,\n 400400,\n 400500,\n 400600,\n 400700,\n 400700,\n 400900,\n 401000,\n 401100,\n 401200,\n 401300,\n 401400,\n 401500,\n 401600,\n 401700,\n 401800,\n 402200,\n 402400,\n 402500,\n 402600,\n 402700,\n 402700,\n 402800,\n 402900,\n 403000,\n 403100,\n 403300,\n 403300,\n 403400,\n 403400,\n 403501,\n 403502,\n 403502,\n 403701,\n 403600,\n 403800,\n 403900,\n 404000,\n 404101,\n 404102,\n 404101,\n 404300,\n 404400,\n 404501,\n 404502,\n 404502,\n 404700,\n 404800,\n 404900,\n 405000,\n 405100,\n 405200,\n 405301,\n 405302,\n 405401,\n 405402,\n 405500,\n 405600,\n 405700,\n 405800,\n 405901,\n 405902,\n 403300,\n 406000,\n 406201,\n 406202,\n 406300,\n 406400,\n 406500,\n 406601,\n 406602,\n 406700,\n 406800,\n 406900,\n 407000,\n 430500,\n 435102,\n 435103,\n 435103,\n 435200,\n 435300,\n 435400,\n 435500,\n 435601,\n 435602,\n 435700,\n 435800,\n 433400,\n 436000,\n 436100,\n 436200,\n 436300,\n 436300,\n 435102,\n 436401,\n 436401,\n 436500,\n 436601,\n 436602,\n 436700,\n 436800,\n 436900,\n 437000,\n 435900,\n 437102,\n 437200,\n 437300,\n 437400,\n 437500,\n 437600,\n 437701,\n 437702,\n 437800,\n 437900,\n 438000,\n 438100,\n 438201,\n 438201,\n 438204,\n 438300,\n 438400,\n 440100,\n 440200,\n 438100,\n 440304,\n 440305,\n 440306,\n 440307,\n 440308,\n 440331,\n 437101,\n 438203,\n 440334,\n 440336,\n 440335,\n 440335,\n 440100,\n 440335,\n 440336,\n 441302,\n 441401,\n 440307,\n 441501,\n 437101,\n 441521,\n 440334,\n 441523,\n 441524,\n 441503,\n 441401,\n 441602,\n 441700,\n 441700,\n 441800,\n 441921,\n 441923,\n 441924,\n 441926,\n 441927,\n 441925,\n 441925,\n 442000,\n 442100,\n 442000,\n 442200,\n 442301,\n 442400,\n 442500,\n 442500,\n 442601,\n 441700,\n 442700,\n 442800,\n 442900,\n 443001,\n 443002,\n 443102,\n 443103,\n 443104,\n 443105,\n 443200,\n 443301,\n 443321,\n 443322,\n 444100,\n 444200,\n 444301,\n 444302,\n 441503,\n 444400,\n 444500,\n 444500,\n 441503,\n 450101,\n 450102,\n 450200,\n 450300,\n 450400,\n 450501,\n 450502,\n 450601,\n 450300,\n 450604,\n 450605,\n 450606,\n 450607,\n 450602,\n 450602,\n 441100,\n 450607,\n 450742,\n 450300,\n 450743,\n 450742,\n 450746,\n 450750,\n 450750,\n 450102,\n 450701,\n 450701,\n 451101,\n 451201,\n 451202,\n 451300,\n 451300,\n 451403,\n 451404,\n 451501,\n 451503,\n 451201,\n 451505,\n 451506,\n 451601,\n 451602,\n 451701,\n 451703,\n 451704,\n 981900,\n 982000,\n 400100,\n 427300,\n 990000,\n 407101,\n 407102,\n 407200,\n 407300,\n 407400,\n 407500,\n 407600,\n 407700,\n 407700,\n 407900,\n 408000,\n 408100,\n 408200,\n 407800,\n 408400,\n 408500,\n 408600,\n 408600,\n 408800,\n 408800,\n 409000,\n 409100,\n 409200,\n 409300,\n 409400,\n 409500,\n 409600,\n 409700,\n 409800,\n 409900,\n 410000,\n 410000,\n 410200,\n 410300,\n 410400,\n 410500,\n 420100,\n 420200,\n 420300,\n 420300,\n 420400,\n 420300,\n 420500,\n 420600,\n 421100,\n 421200,\n 420600,\n 421400,\n 421500,\n 421600,\n 421700,\n 421800,\n 420500,\n 422000,\n 422100,\n 422200,\n 422300,\n 422400,\n 422500,\n 400100,\n 422800,\n 422900,\n 422900,\n 423000,\n 423100,\n 423200,\n 423300,\n 423400,\n 423500,\n 423601,\n 423602,\n 400100,\n 400100,\n 400500,\n 423902,\n 400700,\n 400700,\n 401700,\n 401700,\n 422000,\n 400700,\n 403800,\n 403800,\n 406100,\n 406000,\n 406000,\n 427600,\n 427700,\n 427800,\n 427900,\n 428000,\n 428100,\n 428200,\n 409000,\n 428302,\n 428400,\n 428500,\n 428600,\n 427300,\n 430101,\n 404600,\n 430200,\n 430102,\n 410000,\n 430500,\n 430600,\n 430700,\n 430800,\n 430900,\n 431000,\n 431100,\n 431200,\n 410000,\n 432200,\n 409200,\n 409000,\n 432501,\n 409200,\n 432600,\n 432600,\n 432100,\n 410000,\n 433000,\n 433000,\n 433000,\n 433104,\n 433200,\n 433200,\n 433400,\n 433500,\n 433200,\n 433700,\n 433800,\n 433102,\n 433900]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "raw_xwalk_path = '../tract_to_puma/2010_Census_Tract_to_2010_PUMA.txt'\n",
    "raw_xwalk = pd.read_csv(raw_xwalk_path, delimiter=',')\n",
    "\n",
    "puma_codes_unique = []\n",
    "puma_codes_all = []\n",
    "\n",
    "for tract in tracts:\n",
    "    code = raw_xwalk[(raw_xwalk['STATEFP'] == int(state)) & (raw_xwalk['COUNTYFP'] == int(county)) & (raw_xwalk['TRACTCE'] == int(tract))]['PUMA5CE'].item()\n",
    "    if code not in puma_codes_unique:\n",
    "        puma_codes_unique.append(code)\n",
    "    puma_codes_all.append(int(code))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[103, 102, 104, 106, 107, 105, 108, 109, 110, 101]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puma_codes_unique"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}